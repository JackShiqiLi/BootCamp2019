{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, LeaveOneOut, KFold\n",
    "from sklearn import metrics \n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from pylab import rcParams\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from scipy.stats import randint as sp_randint\n",
    "from scipy.stats import uniform as sp_uniform\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from scipy.stats import uniform as sp_uniform\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Multinomial logistic regression and cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cultivar</th>\n",
       "      <th>alco</th>\n",
       "      <th>malic</th>\n",
       "      <th>ash</th>\n",
       "      <th>alk</th>\n",
       "      <th>magn</th>\n",
       "      <th>tot_phen</th>\n",
       "      <th>flav</th>\n",
       "      <th>nonfl_phen</th>\n",
       "      <th>proanth</th>\n",
       "      <th>color_int</th>\n",
       "      <th>hue</th>\n",
       "      <th>OD280rat</th>\n",
       "      <th>proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>2</td>\n",
       "      <td>11.96</td>\n",
       "      <td>1.09</td>\n",
       "      <td>2.30</td>\n",
       "      <td>21.0</td>\n",
       "      <td>101</td>\n",
       "      <td>3.38</td>\n",
       "      <td>2.14</td>\n",
       "      <td>0.13</td>\n",
       "      <td>1.65</td>\n",
       "      <td>3.21</td>\n",
       "      <td>0.99</td>\n",
       "      <td>3.13</td>\n",
       "      <td>886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>2</td>\n",
       "      <td>11.64</td>\n",
       "      <td>2.06</td>\n",
       "      <td>2.46</td>\n",
       "      <td>21.6</td>\n",
       "      <td>84</td>\n",
       "      <td>1.95</td>\n",
       "      <td>1.69</td>\n",
       "      <td>0.48</td>\n",
       "      <td>1.35</td>\n",
       "      <td>2.80</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.75</td>\n",
       "      <td>680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>2</td>\n",
       "      <td>12.34</td>\n",
       "      <td>2.45</td>\n",
       "      <td>2.46</td>\n",
       "      <td>21.0</td>\n",
       "      <td>98</td>\n",
       "      <td>2.56</td>\n",
       "      <td>2.11</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.31</td>\n",
       "      <td>2.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>3.38</td>\n",
       "      <td>438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>2</td>\n",
       "      <td>12.08</td>\n",
       "      <td>1.39</td>\n",
       "      <td>2.50</td>\n",
       "      <td>22.5</td>\n",
       "      <td>84</td>\n",
       "      <td>2.56</td>\n",
       "      <td>2.29</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.90</td>\n",
       "      <td>0.93</td>\n",
       "      <td>3.19</td>\n",
       "      <td>385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>3</td>\n",
       "      <td>12.79</td>\n",
       "      <td>2.67</td>\n",
       "      <td>2.48</td>\n",
       "      <td>22.0</td>\n",
       "      <td>112</td>\n",
       "      <td>1.48</td>\n",
       "      <td>1.36</td>\n",
       "      <td>0.24</td>\n",
       "      <td>1.26</td>\n",
       "      <td>10.80</td>\n",
       "      <td>0.48</td>\n",
       "      <td>1.47</td>\n",
       "      <td>480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     cultivar   alco  malic   ash   alk  magn  tot_phen  flav  nonfl_phen  \\\n",
       "74          2  11.96   1.09  2.30  21.0   101      3.38  2.14        0.13   \n",
       "88          2  11.64   2.06  2.46  21.6    84      1.95  1.69        0.48   \n",
       "102         2  12.34   2.45  2.46  21.0    98      2.56  2.11        0.34   \n",
       "114         2  12.08   1.39  2.50  22.5    84      2.56  2.29        0.43   \n",
       "150         3  12.79   2.67  2.48  22.0   112      1.48  1.36        0.24   \n",
       "\n",
       "     proanth  color_int   hue  OD280rat  proline  \n",
       "74      1.65       3.21  0.99      3.13      886  \n",
       "88      1.35       2.80  1.00      2.75      680  \n",
       "102     1.31       2.80  0.80      3.38      438  \n",
       "114     1.04       2.90  0.93      3.19      385  \n",
       "150     1.26      10.80  0.48      1.47      480  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drink = pd.read_csv('strongdrink.txt')\n",
    "drink.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = drink[['alco', 'malic', 'tot_phen', 'color_int']].values\n",
    "y = drink['cultivar'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) 75% training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j=1</th>\n",
       "      <th>j=2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>β0</th>\n",
       "      <td>-24.027617</td>\n",
       "      <td>22.780733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>β1</th>\n",
       "      <td>1.701734</td>\n",
       "      <td>-1.466297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>β2</th>\n",
       "      <td>-0.265788</td>\n",
       "      <td>-0.332951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>β3</th>\n",
       "      <td>1.224101</td>\n",
       "      <td>0.663556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>β4</th>\n",
       "      <td>0.022507</td>\n",
       "      <td>-0.922682</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          j=1        j=2\n",
       "β0 -24.027617  22.780733\n",
       "β1   1.701734  -1.466297\n",
       "β2  -0.265788  -0.332951\n",
       "β3   1.224101   0.663556\n",
       "β4   0.022507  -0.922682"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25,random_state=20)\n",
    "clf = LogisticRegression(random_state=0, solver='lbfgs',\n",
    "                         multi_class='multinomial').fit(X_train, y_train)\n",
    "\n",
    "parameters = pd.DataFrame({\"j=1\":np.append(clf.intercept_[0],clf.coef_[0]),\n",
    "                           \"j=2\":np.append(clf.intercept_[1],clf.coef_[1])},\n",
    "                          index=[\"β0\",\"β1\",'β2','β3','β4'])\n",
    "\n",
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.87      1.00      0.93        13\n",
      "           2       1.00      0.90      0.95        21\n",
      "           3       1.00      1.00      1.00        10\n",
      "\n",
      "    accuracy                           0.95        44\n",
      "   macro avg       0.96      0.97      0.96        44\n",
      "weighted avg       0.96      0.95      0.96        44\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred=clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    71\n",
       "1    59\n",
       "3    46\n",
       "Name: cultivar, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drink['cultivar'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.045454545454545456\n"
     ]
    }
   ],
   "source": [
    "print(mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Error rates for j=1 is 13%, j=2 is 0%.\n",
    "- category 2 is best predicted as category 3 is the baseline class.\n",
    "- The most accurately predicdted category is not the one with the most observations.\n",
    "- MSE is 0.04545."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) leave-one-out cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_loo = X.shape[0]\n",
    "loo = LeaveOneOut()\n",
    "loo.get_n_splits(X)\n",
    "MSE_vec = np.zeros(N_loo)\n",
    "y_test_vec = np.zeros(N_loo)\n",
    "y_pred_vec = np.zeros(N_loo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.84      0.78      0.81        59\n",
      "         2.0       0.83      0.89      0.86        71\n",
      "         3.0       0.96      0.93      0.95        46\n",
      "\n",
      "    accuracy                           0.86       176\n",
      "   macro avg       0.87      0.87      0.87       176\n",
      "weighted avg       0.86      0.86      0.86       176\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in loo.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    LogReg = LogisticRegression(solver = 'liblinear', multi_class='auto')\n",
    "    LogReg.fit(X_train, y_train)\n",
    "    y_pred = LogReg.predict(X_test)\n",
    "    MSE_vec[test_index] = (y_test - y_pred) ** 2\n",
    "#     print('MSE for test set', test_index, ' is', MSE_vec[test_index])\n",
    "    y_test_vec[test_index] = y_test\n",
    "    y_pred_vec[test_index] = y_pred\n",
    "\n",
    "print(classification_report(y_test_vec, y_pred_vec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error rates is 16% for j=1, 17% for j = 0, 4% for j = 3, much worse than the 75% train test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOOCV MSE = 0.1875\n"
     ]
    }
   ],
   "source": [
    "MSE_loo = MSE_vec.mean()\n",
    "print('LOOCV MSE =', MSE_loo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) k-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 4\n",
    "kf = KFold(n_splits = k, shuffle = True, random_state = 10)\n",
    "kf.get_n_splits(X)\n",
    "N_loo = X.shape[0]\n",
    "MSE_vec_kf = np.zeros(k)\n",
    "y_test_vec_kf = np.zeros(N_loo)\n",
    "y_pred_vec_kf = np.zeros(N_loo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for test set 0 is 0.22727272727272727\n",
      "MSE for test set 1 is 0.11363636363636363\n",
      "MSE for test set 2 is 0.045454545454545456\n",
      "MSE for test set 3 is 0.045454545454545456\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.87      0.93      0.90        59\n",
      "         2.0       0.91      0.87      0.89        71\n",
      "         3.0       0.96      0.93      0.95        46\n",
      "\n",
      "    accuracy                           0.91       176\n",
      "   macro avg       0.91      0.91      0.91       176\n",
      "weighted avg       0.91      0.91      0.91       176\n",
      "\n"
     ]
    }
   ],
   "source": [
    "k_ind = int(0)\n",
    "for train_index, test_index in kf.split(X):\n",
    "#     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "#     print('k index=', k_ind)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    Mlogit = LogisticRegression(random_state=0, solver='newton-cg', multi_class='multinomial')\n",
    "    Mlogit.fit(X_train, y_train)\n",
    "    y_pred = Mlogit.predict(X_test)\n",
    "\n",
    "    MSE_vec_kf[k_ind] = mean_squared_error(y_test, y_pred)\n",
    "    y_test_vec_kf[test_index] = y_test\n",
    "    y_pred_vec_kf[test_index] = y_pred\n",
    "    print('MSE for test set', k_ind, 'is', MSE_vec_kf[k_ind])\n",
    "    k_ind += 1\n",
    "    \n",
    "print(classification_report(y_test_vec_kf, y_pred_vec_kf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error rate is 13% for j=1, 9% for j=2, 4% for j=3, worse than the 75% train test split but better than LOOCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-fold MSE = 0.10795454545454546\n"
     ]
    }
   ],
   "source": [
    "MSE_kf = MSE_vec_kf.mean()\n",
    "print('K-fold MSE =', MSE_kf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>biden</th>\n",
       "      <th>female</th>\n",
       "      <th>age</th>\n",
       "      <th>educ</th>\n",
       "      <th>dem</th>\n",
       "      <th>rep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1738</th>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "      <td>83</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098</th>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1617</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>69</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839</th>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      biden  female  age  educ  dem  rep\n",
       "91       50       1   20    12    0    0\n",
       "1738     85       1   83    13    1    0\n",
       "1098     50       1   60    14    1    0\n",
       "1617     70       1   69    17    1    0\n",
       "839      85       0   50    12    1    0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biden = pd.read_csv('biden.csv')\n",
    "biden.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = biden[['female', 'age', 'educ', 'dem', 'rep']].values\n",
    "y = biden['biden'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) 70% training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70% training set MSE = 386.8938634284023\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3,random_state=20)\n",
    "\n",
    "biden_tree = DecisionTreeRegressor(max_depth=3, min_samples_leaf=5)\n",
    "biden_tree.fit(X_train, y_train)\n",
    "y_pred = biden_tree.predict(X_test)\n",
    "print('70% training set MSE =', mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Tune hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Best Estimator = DecisionTreeRegressor(criterion='mse', max_depth=3, max_features=None,\n",
      "                      max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=18,\n",
      "                      min_samples_split=11, min_weight_fraction_leaf=0.0,\n",
      "                      presort=False, random_state=None, splitter='best')\n",
      "Random Best Params (Optimal Tuning Parameter Values) = {'max_depth': 3, 'min_samples_leaf': 18, 'min_samples_split': 11}\n",
      "Random Best Score (MSE) = 401.6903602232667\n"
     ]
    }
   ],
   "source": [
    "param_dist1 = {'max_depth': [3, 10],\n",
    "               'min_samples_split': sp_randint(2, 20),\n",
    "               'min_samples_leaf': sp_randint(2, 20)}\n",
    "\n",
    "random_search = \\\n",
    "    RandomizedSearchCV(biden_tree, param_distributions=param_dist1,\n",
    "                       n_iter=100, n_jobs=-1, cv=5, random_state=20,\n",
    "                       scoring='neg_mean_squared_error')\n",
    "\n",
    "random_search.fit(X, y)  \n",
    "print('Random Best Estimator =', random_search.best_estimator_)\n",
    "print('Random Best Params (Optimal Tuning Parameter Values) =', random_search.best_params_)\n",
    "print('Random Best Score (MSE) =', -random_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Tune hyperparameters for random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Best Estimator = RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=3,\n",
      "                      max_features=3, max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=18, min_samples_split=16,\n",
      "                      min_weight_fraction_leaf=0.0, n_estimators=200,\n",
      "                      n_jobs=None, oob_score=False, random_state=20, verbose=0,\n",
      "                      warm_start=False)\n",
      "Random Best Params (Optimal Tuning Parameter Values) = {'max_depth': 3, 'max_features': 3, 'min_samples_leaf': 18, 'min_samples_split': 16, 'n_estimators': 200}\n",
      "Random Best Score (MSE) = 397.4387994329025\n"
     ]
    }
   ],
   "source": [
    "biden_RF = RandomForestRegressor(random_state = 20)\n",
    "\n",
    "param_dist2 = {'n_estimators': [10, 200],\n",
    "               'max_depth': [3, 10],\n",
    "               'min_samples_split': sp_randint(2, 20),\n",
    "               'min_samples_leaf': sp_randint(2, 20),\n",
    "               'max_features': sp_randint(1, 5)}\n",
    "\n",
    "random_search_RF = \\\n",
    "    RandomizedSearchCV(biden_RF, param_distributions=param_dist2,\n",
    "                       n_iter=100, n_jobs=-1, cv=5, random_state=20,\n",
    "                       scoring='neg_mean_squared_error')\n",
    "\n",
    "random_search_RF.fit(X, y)  \n",
    "print('Random Best Estimator =', random_search_RF.best_estimator_)\n",
    "print('Random Best Params (Optimal Tuning Parameter Values) =', random_search_RF.best_params_)\n",
    "print('Random Best Score (MSE) =', -random_search_RF.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Classifier \"horse\" race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>year</th>\n",
       "      <th>origin</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>13.0</td>\n",
       "      <td>8</td>\n",
       "      <td>400.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>4746</td>\n",
       "      <td>12.0</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>ford country squire (sw)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>31.9</td>\n",
       "      <td>4</td>\n",
       "      <td>89.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>1925</td>\n",
       "      <td>14.0</td>\n",
       "      <td>79</td>\n",
       "      <td>2</td>\n",
       "      <td>vw rabbit custom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>17.0</td>\n",
       "      <td>6</td>\n",
       "      <td>231.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>3907</td>\n",
       "      <td>21.0</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>buick century</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>19.0</td>\n",
       "      <td>6</td>\n",
       "      <td>225.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>3264</td>\n",
       "      <td>16.0</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>plymouth valiant custom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>30.0</td>\n",
       "      <td>4</td>\n",
       "      <td>98.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>2155</td>\n",
       "      <td>16.5</td>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>chevrolet chevette</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      mpg  cylinders  displacement  horsepower  weight  acceleration  year  \\\n",
       "43   13.0          8         400.0       170.0    4746          12.0    71   \n",
       "293  31.9          4          89.0        71.0    1925          14.0    79   \n",
       "160  17.0          6         231.0       110.0    3907          21.0    75   \n",
       "152  19.0          6         225.0        95.0    3264          16.0    75   \n",
       "266  30.0          4          98.0        68.0    2155          16.5    78   \n",
       "\n",
       "     origin                      name  \n",
       "43        1  ford country squire (sw)  \n",
       "293       2          vw rabbit custom  \n",
       "160       1             buick century  \n",
       "152       1   plymouth valiant custom  \n",
       "266       1        chevrolet chevette  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto = pd.read_csv('auto.csv', na_values='?')\n",
    "auto.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto['mpg'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>year</th>\n",
       "      <th>origin</th>\n",
       "      <th>name</th>\n",
       "      <th>mpg_high</th>\n",
       "      <th>orgn1</th>\n",
       "      <th>orgn2</th>\n",
       "      <th>const</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>26.0</td>\n",
       "      <td>4</td>\n",
       "      <td>79.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1963</td>\n",
       "      <td>15.5</td>\n",
       "      <td>74</td>\n",
       "      <td>2</td>\n",
       "      <td>volkswagen dasher</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>19.0</td>\n",
       "      <td>6</td>\n",
       "      <td>225.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>3264</td>\n",
       "      <td>16.0</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>plymouth valiant custom</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>20.0</td>\n",
       "      <td>6</td>\n",
       "      <td>225.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3651</td>\n",
       "      <td>17.7</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>dodge aspen se</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>400.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>4278</td>\n",
       "      <td>9.5</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "      <td>pontiac grand prix</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>32.3</td>\n",
       "      <td>4</td>\n",
       "      <td>97.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>2065</td>\n",
       "      <td>17.8</td>\n",
       "      <td>81</td>\n",
       "      <td>3</td>\n",
       "      <td>subaru</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      mpg  cylinders  displacement  horsepower  weight  acceleration  year  \\\n",
       "142  26.0          4          79.0        67.0    1963          15.5    74   \n",
       "152  19.0          6         225.0        95.0    3264          16.0    75   \n",
       "199  20.0          6         225.0       100.0    3651          17.7    76   \n",
       "116  16.0          8         400.0       230.0    4278           9.5    73   \n",
       "346  32.3          4          97.0        67.0    2065          17.8    81   \n",
       "\n",
       "     origin                     name  mpg_high  orgn1  orgn2  const  \n",
       "142       2        volkswagen dasher         1      0      1      1  \n",
       "152       1  plymouth valiant custom         0      1      0      1  \n",
       "199       1           dodge aspen se         0      1      0      1  \n",
       "116       1       pontiac grand prix         0      1      0      1  \n",
       "346       3                   subaru         1      0      0      1  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto['mpg_high'] = np.where(auto['mpg'] >= auto['mpg'].median(), 1, 0)\n",
    "auto[\"orgn1\"] = np.where(auto[\"origin\"] == 1, 1, 0)\n",
    "auto[\"orgn2\"] = np.where(auto[\"origin\"] == 2, 1, 0)\n",
    "auto['const'] = 1\n",
    "auto.dropna(inplace = True)\n",
    "auto.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) K-fold logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = auto[['const', 'cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'year', 'orgn1', 'orgn2']].values.astype(float)\n",
    "y = auto['mpg_high'].values.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 4\n",
    "kf_log = KFold(n_splits=k, shuffle=True, random_state=25)\n",
    "kf_log.get_n_splits(X)\n",
    "N_loo = X.shape[0]\n",
    "MSE_vec_kf = np.zeros(k)\n",
    "y_test_vec_kf = np.zeros(N_loo)\n",
    "y_pred_vec_kf = np.zeros(N_loo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for test set 0 is 0.1326530612244898\n",
      "MSE for test set 1 is 0.08163265306122448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/scipy/optimize/linesearch.py:462: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/scipy/optimize/linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/scipy/optimize/linesearch.py:462: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/scipy/optimize/linesearch.py:313: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for test set 2 is 0.07142857142857142\n",
      "MSE for test set 3 is 0.07142857142857142\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.88      0.91       196\n",
      "         1.0       0.89      0.94      0.91       196\n",
      "\n",
      "    accuracy                           0.91       392\n",
      "   macro avg       0.91      0.91      0.91       392\n",
      "weighted avg       0.91      0.91      0.91       392\n",
      "\n",
      "MSE = 0.08928571428571427\n"
     ]
    }
   ],
   "source": [
    "k_ind = int(0)\n",
    "for train_index, test_index in kf_log.split(X):\n",
    "#     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "#     print('k index=', k_ind)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    Mlogit = LogisticRegression(random_state=0, solver='newton-cg', multi_class='multinomial')\n",
    "    Mlogit.fit(X_train, y_train)\n",
    "    y_pred = Mlogit.predict(X_test)\n",
    "\n",
    "    MSE_vec_kf[k_ind] = mean_squared_error(y_test, y_pred)\n",
    "    y_test_vec_kf[test_index] = y_test\n",
    "    y_pred_vec_kf[test_index] = y_pred\n",
    "    print('MSE for test set', k_ind, 'is', MSE_vec_kf[k_ind])\n",
    "    k_ind += 1\n",
    "    \n",
    "print(classification_report(y_test_vec_kf, y_pred_vec_kf))\n",
    "print('MSE =', MSE_vec_kf.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error rate for mpg_high = 1 is 0.11, for mpg_high = 0 is 0.06"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Best Estimator = RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=3,\n",
      "                      max_features=1, max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=5, min_samples_split=7,\n",
      "                      min_weight_fraction_leaf=0.0, n_estimators=10,\n",
      "                      n_jobs=None, oob_score=False, random_state=25, verbose=0,\n",
      "                      warm_start=False)\n",
      "Random Best Params (Optimal Tuning Parameter Values) = {'max_depth': 3, 'max_features': 1, 'min_samples_leaf': 5, 'min_samples_split': 7, 'n_estimators': 10}\n",
      "Random Best Score (MSE) = 0.09445434608069206\n"
     ]
    }
   ],
   "source": [
    "auto_RF = RandomForestRegressor(random_state = 25)\n",
    "\n",
    "param_dist = {'n_estimators': [10, 200],\n",
    "               'max_depth': [3, 8],\n",
    "               'min_samples_split': sp_randint(2, 20),\n",
    "               'min_samples_leaf': sp_randint(2, 20),\n",
    "               'max_features': sp_randint(1, 8)}\n",
    "\n",
    "random_search_RF = \\\n",
    "    RandomizedSearchCV(auto_RF, param_distributions=param_dist,\n",
    "                       n_iter=100, n_jobs=-1, cv=4, random_state=25,\n",
    "                       scoring='neg_mean_squared_error')\n",
    "\n",
    "random_search_RF.fit(X, y)  \n",
    "print('Random Best Estimator =', random_search_RF.best_estimator_)\n",
    "print('Random Best Params (Optimal Tuning Parameter Values) =', random_search_RF.best_params_)\n",
    "print('Random Best Score (MSE) =', -random_search_RF.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) SVC with tuning hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Best Estimator = SVC(C=0.3377990724342859, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=False,\n",
      "    tol=0.001, verbose=False)\n",
      "Random Best Params (Optimal Tuning Parameter Values) = {'C': 0.3377990724342859, 'gamma': 'scale', 'shrinking': False}\n",
      "Random Best Score (MSE) = 0.11734693877551021\n"
     ]
    }
   ],
   "source": [
    "auto_SVC = SVC(kernel = 'rbf')\n",
    "\n",
    "param_dist4 = {'C': sp_uniform(loc=0.2, scale=4.0),\n",
    "               'gamma': ['scale', 'auto'],\n",
    "               'shrinking': [True, False]}\n",
    "\n",
    "random_search_SVC = \\\n",
    "    RandomizedSearchCV(auto_SVC, param_distributions=param_dist4,\n",
    "                       n_iter=100, n_jobs=-1, cv=4, random_state=25,\n",
    "                       scoring='neg_mean_squared_error')\n",
    "\n",
    "random_search_SVC.fit(X, y)  \n",
    "print('Random Best Estimator =', random_search_SVC.best_estimator_)\n",
    "print('Random Best Params (Optimal Tuning Parameter Values) =', random_search_SVC.best_params_)\n",
    "print('Random Best Score (MSE) =', -random_search_SVC.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on MSE, the best model is 4-fold logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Neural network horse race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cultivar</th>\n",
       "      <th>alco</th>\n",
       "      <th>malic</th>\n",
       "      <th>ash</th>\n",
       "      <th>alk</th>\n",
       "      <th>magn</th>\n",
       "      <th>tot_phen</th>\n",
       "      <th>flav</th>\n",
       "      <th>nonfl_phen</th>\n",
       "      <th>proanth</th>\n",
       "      <th>color_int</th>\n",
       "      <th>hue</th>\n",
       "      <th>OD280rat</th>\n",
       "      <th>proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1</td>\n",
       "      <td>13.73</td>\n",
       "      <td>1.50</td>\n",
       "      <td>2.70</td>\n",
       "      <td>22.5</td>\n",
       "      <td>101</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.25</td>\n",
       "      <td>0.29</td>\n",
       "      <td>2.38</td>\n",
       "      <td>5.70</td>\n",
       "      <td>1.19</td>\n",
       "      <td>2.71</td>\n",
       "      <td>1285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>3</td>\n",
       "      <td>12.87</td>\n",
       "      <td>4.61</td>\n",
       "      <td>2.48</td>\n",
       "      <td>21.5</td>\n",
       "      <td>86</td>\n",
       "      <td>1.70</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.86</td>\n",
       "      <td>7.65</td>\n",
       "      <td>0.54</td>\n",
       "      <td>1.86</td>\n",
       "      <td>625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>2</td>\n",
       "      <td>12.51</td>\n",
       "      <td>1.73</td>\n",
       "      <td>1.98</td>\n",
       "      <td>20.5</td>\n",
       "      <td>85</td>\n",
       "      <td>2.20</td>\n",
       "      <td>1.92</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1.48</td>\n",
       "      <td>2.94</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.57</td>\n",
       "      <td>672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>3</td>\n",
       "      <td>12.53</td>\n",
       "      <td>5.51</td>\n",
       "      <td>2.64</td>\n",
       "      <td>25.0</td>\n",
       "      <td>96</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.63</td>\n",
       "      <td>1.10</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.82</td>\n",
       "      <td>1.69</td>\n",
       "      <td>515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>2</td>\n",
       "      <td>12.29</td>\n",
       "      <td>2.83</td>\n",
       "      <td>2.22</td>\n",
       "      <td>18.0</td>\n",
       "      <td>88</td>\n",
       "      <td>2.45</td>\n",
       "      <td>2.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.99</td>\n",
       "      <td>2.15</td>\n",
       "      <td>1.15</td>\n",
       "      <td>3.30</td>\n",
       "      <td>290</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     cultivar   alco  malic   ash   alk  magn  tot_phen  flav  nonfl_phen  \\\n",
       "30          1  13.73   1.50  2.70  22.5   101      3.00  3.25        0.29   \n",
       "146         3  12.87   4.61  2.48  21.5    86      1.70  0.65        0.47   \n",
       "104         2  12.51   1.73  1.98  20.5    85      2.20  1.92        0.32   \n",
       "136         3  12.53   5.51  2.64  25.0    96      1.79  0.60        0.63   \n",
       "93          2  12.29   2.83  2.22  18.0    88      2.45  2.25        0.25   \n",
       "\n",
       "     proanth  color_int   hue  OD280rat  proline  \n",
       "30      2.38       5.70  1.19      2.71     1285  \n",
       "146     0.86       7.65  0.54      1.86      625  \n",
       "104     1.48       2.94  1.04      3.57      672  \n",
       "136     1.10       5.00  0.82      1.69      515  \n",
       "93      1.99       2.15  1.15      3.30      290  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drink.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) scatter plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplots(1,1, figsize = (10,7))\n",
    "for i in [1,2,3]:\n",
    "    data = drink[drink['cultivar'] == i]\n",
    "    plt.scatter(data['alco'], data['color_int'], label = 'cultivar = {}'.format(i))\n",
    "    \n",
    "plt.xlabel('Alcohol', fontsize = 15)\n",
    "plt.ylabel('Color Intensity', fontsize = 15)\n",
    "plt.title('Alcohol vs Color Intensity', fontsize = 20)\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = drink[['alco', 'malic', 'tot_phen', 'color_int']].values\n",
    "y = drink['cultivar'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Best Logistic Estimator = LogisticRegression(C=2.665871587495725, class_weight=None, dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l1',\n",
      "                   random_state=25, solver='liblinear', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "Random Best Logistic Params (Optimal Tuning Parameter Values) = {'C': 2.665871587495725, 'penalty': 'l1'}\n",
      "Random Best Logistic Score (MSE) = 0.11931818181818182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "drink_log = LogisticRegression(solver = 'liblinear', multi_class = 'auto', random_state = 25)\n",
    "\n",
    "param_dist_log = {'penalty': ['l1', 'l2'], \n",
    "                  'C': sp_uniform(0.1, 10.0)}\n",
    "\n",
    "random_search_log = RandomizedSearchCV(drink_log, param_dist_log, iid = True,\n",
    "                                       n_iter = 200, n_jobs = -1, cv = 5,\n",
    "                                       random_state = 25, scoring = 'neg_mean_squared_error')\n",
    "\n",
    "random_search_log.fit(X, y)\n",
    "print('Random Best Logistic Estimator =', random_search_log.best_estimator_)\n",
    "print('Random Best Logistic Params (Optimal Tuning Parameter Values) =', random_search_log.best_params_)\n",
    "print('Random Best Logistic Score (MSE) =', -random_search_log.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Best RF Estimator = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=3, max_features=1, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=13, min_samples_split=18,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=176,\n",
      "                       n_jobs=None, oob_score=False, random_state=25, verbose=0,\n",
      "                       warm_start=False)\n",
      "Random Best RF Params (Optimal Tuning Parameter Values) = {'max_depth': 3, 'max_features': 1, 'min_samples_leaf': 13, 'min_samples_split': 18, 'n_estimators': 176}\n",
      "Random Best RF Score (MSE) = 0.13068181818181818\n"
     ]
    }
   ],
   "source": [
    "drink_RF = RandomForestClassifier(random_state = 25)\n",
    "\n",
    "param_dist_RF = {'n_estimators': sp_randint(10, 200),\n",
    "                 'max_depth': sp_randint(2, 4),\n",
    "                 'min_samples_split': sp_randint(2, 20),\n",
    "                 'min_samples_leaf': sp_randint(2, 20),\n",
    "                 'max_features': sp_randint(1, 4)}\n",
    "\n",
    "random_search_RF = RandomizedSearchCV(drink_RF, param_dist_RF, iid = True,\n",
    "                                       n_iter = 200, n_jobs = -1, cv = 5,\n",
    "                                       random_state = 25, scoring = 'neg_mean_squared_error')\n",
    "\n",
    "random_search_RF.fit(X, y)\n",
    "print('Random Best RF Estimator =', random_search_RF.best_estimator_)\n",
    "print('Random Best RF Params (Optimal Tuning Parameter Values) =', random_search_RF.best_params_)\n",
    "print('Random Best RF Score (MSE) =', -random_search_RF.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Best SVC Estimator = SVC(C=9.58835943424229, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=25, shrinking=True, tol=0.001,\n",
      "    verbose=False)\n",
      "Random Best SVC Params (Optimal Tuning Parameter Values) = {'C': 9.58835943424229, 'gamma': 'scale', 'shrinking': True}\n",
      "Random Best SVC Score (MSE) = 0.13636363636363635\n"
     ]
    }
   ],
   "source": [
    "drink_SVC = SVC(random_state = 25)\n",
    "\n",
    "param_dist_SVC = {'C': sp_uniform(loc=0.1, scale=10.0),\n",
    "                  'gamma': ['scale', 'auto'],\n",
    "                  'shrinking': [True, False]}\n",
    "\n",
    "random_search_SVC = RandomizedSearchCV(drink_SVC, param_dist_SVC, iid = True,\n",
    "                                       n_iter = 200, n_jobs = -1, cv = 5,\n",
    "                                       random_state = 25, scoring = 'neg_mean_squared_error')\n",
    "\n",
    "random_search_SVC.fit(X, y)\n",
    "print('Random Best SVC Estimator =', random_search_SVC.best_estimator_)\n",
    "print('Random Best SVC Params (Optimal Tuning Parameter Values) =', random_search_SVC.best_params_)\n",
    "print('Random Best SVC Score (MSE) =', -random_search_SVC.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e) MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Best MLP Estimator = MLPClassifier(activation='relu', alpha=2.158912119744818, batch_size='auto',\n",
      "              beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "              hidden_layer_sizes=68, learning_rate='constant',\n",
      "              learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "              random_state=25, shuffle=True, solver='adam', tol=0.0001,\n",
      "              validation_fraction=0.1, verbose=False, warm_start=False)\n",
      "Random Best MLP Params (Optimal Tuning Parameter Values) = {'activation': 'relu', 'alpha': 2.158912119744818, 'hidden_layer_sizes': 68}\n",
      "Random Best MLP Score (MSE) = 0.19318181818181818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "drink_MLP = MLPClassifier(random_state = 25)\n",
    "\n",
    "param_dist_MLP = {'hidden_layer_sizes': sp_randint(1, 100),\n",
    "                  'activation': ['logistic', 'relu'],\n",
    "                  'alpha': sp_uniform(0.1, 10.0)}\n",
    "\n",
    "random_search_MLP = RandomizedSearchCV(drink_MLP, param_dist_MLP, iid = True,\n",
    "                                       n_iter = 200, n_jobs = -1, cv = 5,\n",
    "                                       random_state = 25, scoring = 'neg_mean_squared_error')\n",
    "\n",
    "random_search_MLP.fit(X, y)\n",
    "print('Random Best MLP Estimator =', random_search_MLP.best_estimator_)\n",
    "print('Random Best MLP Params (Optimal Tuning Parameter Values) =', random_search_MLP.best_params_)\n",
    "print('Random Best MLP Score (MSE) =', -random_search_MLP.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression gives the lowest MSE and might be the best model.  \n",
    "However, we notice that MLP classifier have not converge with 200 iterations, hence it may give better results if we allow for more iterations. (but also note that logistic regression does not converge as well)  \n",
    "Furthermore, there might be overfitting problem with logistic regression."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
